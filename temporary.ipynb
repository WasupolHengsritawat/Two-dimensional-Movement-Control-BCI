{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psychopy import visual, core\n",
    "import numpy as np\n",
    "\n",
    "t_cross = 2\n",
    "t_cue = 3\n",
    "t_rest_mean = 2\n",
    "\n",
    "## Hyperparameters --------------------------------------------------------------------------------------------------------\n",
    "# Cue Parameters --------------------------------------------------------------\n",
    "arrow_size = 750             # Arrow Size\n",
    "n_trials  = [15, 15, 15, 0]  # Number of each class (None, Right, Left, Down)\n",
    "trial_length = 3             # Length of arrow display [sec]\n",
    "blink_freq = 0               # Arrow blinking frequency [Hz]\n",
    "\n",
    "# Classification Hyperparameters ----------------------------------------------\n",
    "# -- |Train Data| --\n",
    "participant_id = 0\n",
    "session = 3\n",
    "initial_run = 1\n",
    "n_run = 5\n",
    "\n",
    "# -- |Time Parameters| --\n",
    "# Offline\n",
    "tmin= -0.1\n",
    "tmax= 3\n",
    "t_baseline_offline = 0.1\n",
    "# Online\n",
    "classification_cycle_period = 0.2\n",
    "classification_window_length = 0.5\n",
    "t_baseline_online = 0.1\n",
    "\n",
    "## Cue Preparation --------------------------------------------------------------------------------------------------------\n",
    "# -- |Create random label sequence| --\n",
    "labels = np.zeros(n_trials[0], dtype='int')\n",
    "for i in range(1,len(n_trials)):\n",
    "    labels = np.concatenate((labels,np.full(n_trials[i],i, dtype='int')))\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "# -- |Define Display| --\n",
    "win = visual.Window(color=(-255, -255, -255), fullscr=True, units = 'pix', screen = 1)\n",
    "\n",
    "# -- |Shapes| --\n",
    "def box(pos = (0,0), x = 0, y = 0, color = 'red', size = 1):\n",
    "    x_neg = x if x < 0 else 0\n",
    "    x_pos = x if x > 0 else 0\n",
    "\n",
    "    y_neg = y if y < 0 else 0\n",
    "    y_pos = y if y > 0 else 0\n",
    "\n",
    "    return visual.ShapeStim(win, vertices=[(x_neg, -30 + y_neg),(x_pos, -30 + y_neg),(x_pos, 30 + y_pos),(x_neg, 30 + y_pos)], interpolate=True, fillColor=color, pos=pos, size=size)\n",
    "cross = visual.TextStim(win, text='+', height=50)\n",
    "\n",
    "# Arrow Vertices\n",
    "arrow = [[(0,0)],                                                                   # 0 - None\n",
    "         [(-0.2,0.05),(-0.2,-0.05),(0,-0.05),(0,-0.1),(.2,0),(0,0.1),(0,0.05)],     # 1 - Right\n",
    "         [(.2,0.05),(.2,-0.05),(0,-0.05),(0,-0.1),(-0.2,0),(0,0.1),(0,0.05)],       # 2 - Left\n",
    "         [(0.05,0.2),(-0.05,0.2),(-0.05,0),(-0.1,0),(0,-.2),(0.1,0),(0.05,0)]]      # 3 - Down\n",
    "# Arrow Position\n",
    "arrow_pos = np.array([(0,0),(0.3,0),(-0.3,0),(0,-0.3)]) # [None, Right, Left, Down]\n",
    "\n",
    "# Arrow Shapes\n",
    "arrows = []\n",
    "for i in range(len(arrow)):\n",
    "    arrows.append(visual.ShapeStim(win, vertices=arrow[i], interpolate=True, fillColor='red', pos=(0,0), size=arrow_size))\n",
    "\n",
    "def state(s):\n",
    "    state.value = s\n",
    "def t_sm():\n",
    "    t_sm.counter += classification_cycle_period\n",
    "\n",
    "t_sm.counter = 0    # Initial State Machine Time\n",
    "state(0)            # Initial State\n",
    "cue_update_flag = False\n",
    "\n",
    "def cue_state_machine(trial):\n",
    "    if state.value == 0:\n",
    "        cross.draw()\n",
    "        t_sm()\n",
    "        if t_sm.counter > t_cross:\n",
    "            t_sm.counter = 0\n",
    "            state(1)\n",
    "    elif state.value == 1:\n",
    "        arrows[labels[trial]].draw() \n",
    "        t_sm()\n",
    "        if t_sm.counter > t_cue:\n",
    "            t_sm.counter = 0\n",
    "            state(2)\n",
    "            t_rest = (t_rest_mean - 0.5) + np.random.rand()\n",
    "    elif state.value == 2:\n",
    "        t_sm()\n",
    "        if t_sm.counter > t_rest:\n",
    "            t_sm.counter = 0\n",
    "            cue_update_flag = True\n",
    "            state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(5//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#751818', 'gray'], dtype='<U7')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pscores = np.array([2,8])\n",
    "k = 3\n",
    "\n",
    "np.where(np.array([k,k]) < Pscores,'#751818','gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "b = 1\n",
    "\n",
    "c = a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores calculation simulation (Double model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Model Performance\n",
      "Confusion Matrix\n",
      "--------------------------------------\n",
      "|            |       Predicted       |\n",
      "|            -------------------------   Accuracy  = 0.4288888888888889\n",
      "|            |     P     |     N     |\n",
      "--------------------------------------   Precision = 0.24564183835182252\n",
      "|        | P |    155    |    295    |   Recall    = 0.34444444444444444\n",
      "| Actual -----------------------------\n",
      "|        | N |    476    |    424    |   F1-score  = 0.28677150786308975\n",
      "--------------------------------------\n",
      "Right Model Performance\n",
      "Confusion Matrix\n",
      "--------------------------------------\n",
      "|            |       Predicted       |\n",
      "|            -------------------------   Accuracy  = 0.585925925925926\n",
      "|            |     P     |     N     |\n",
      "--------------------------------------   Precision = 0.41362916006339145\n",
      "|        | P |    261    |    189    |   Recall    = 0.58\n",
      "| Actual -----------------------------\n",
      "|        | N |    370    |    530    |   F1-score  = 0.4828862164662349\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.585925925925926, 0.41362916006339145, 0.58, 0.4828862164662349]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials  = [15, 15, 15, 0]     # Number of each class (None, Right, Left, Down)\n",
    "t_cue = 3\n",
    "classification_cycle_period = 0.1\n",
    "\n",
    "events_id = {'none': 0, 'right': 1, 'left': 2}\n",
    "\n",
    "def confusion_matrix(TP,FN,FP,TN):\n",
    "    # -- |Results calculation| --\n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = np.NaN\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = np.NaN\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "        \n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------')\n",
    "    print('|            |       Predicted       |')\n",
    "    print('|            -------------------------   Accuracy  = {0:}'.format(accuracy))\n",
    "    print('|            |     P     |     N     |')\n",
    "    print('--------------------------------------   Precision = {0:}'.format(precision))\n",
    "    print(\"|        | P |   {0:^5d}   |   {1:^5d}   |   Recall    = {2:}\".format(TP, FN, recall))\n",
    "    print('| Actual -----------------------------')\n",
    "    print(\"|        | N |   {0:^5d}   |   {1:^5d}   |   F1-score  = {2:}\".format(FP, TN, f1))\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "# -- |Create random label sequence| --\n",
    "labels = np.zeros(n_trials[0], dtype='int')\n",
    "for i in range(1,len(n_trials)):\n",
    "    labels = np.concatenate((labels,np.full(n_trials[i],i, dtype='int')))\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "j = 0\n",
    "p = []\n",
    "Pscores = np.array([0,0])\n",
    "Nscores = np.array([0,0])\n",
    "Pscores_history = []\n",
    "Nscores_history = []\n",
    "while j < len(labels):\n",
    "    label = labels[j]\n",
    "    for i in range(2):\n",
    "        Pscores[i] = np.random.randint(0,30)\n",
    "        Nscores[i] = 30 - Pscores[i]\n",
    "    Pscores_history.append([label, Pscores])\n",
    "    Nscores_history.append([label, Nscores])\n",
    "    Pscores = np.array([0,0])\n",
    "    Nscores = np.array([0,0])\n",
    "    j += 1\n",
    "\n",
    "Pscores_history = np.array(Pscores_history, dtype='object')\n",
    "Nscores_history = np.array(Nscores_history, dtype='object')\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "for l in range(np.max(list(events_id.values())) + 1):\n",
    "    Pscores_total = np.array([sh[1] for sh in Pscores_history if sh[0] == l])\n",
    "    Pscores_total = np.sum(Pscores_total, axis = 0)\n",
    "    positive.append(Pscores_total)\n",
    "\n",
    "    Nscores_total = np.array([sh[1] for sh in Nscores_history if sh[0] == l])\n",
    "    Nscores_total = np.sum(Nscores_total, axis = 0)\n",
    "    negative.append(Nscores_total)\n",
    "\n",
    "positive = np.array(positive)\n",
    "negative = np.array(negative)\n",
    "print('Left Model Performance')\n",
    "confusion_matrix(positive[events_id['left']][0],negative[events_id['left']][0],(np.sum(positive[:,0]) - positive[events_id['left']])[0],(np.sum(negative[:,0]) - negative[events_id['left']])[0])\n",
    "print('Right Model Performance')\n",
    "confusion_matrix(positive[events_id['right']][1],negative[events_id['right']][1],(np.sum(positive[:,0]) - positive[events_id['right']])[1],(np.sum(negative[:,0]) - negative[events_id['right']])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores calculation simulation (Single model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "--------------------------------------------------\n",
      "|            |             Predicted             |\n",
      "|            -------------------------------------\n",
      "|            |     N     |     R     |     L     |\n",
      "--------------------------------------------------\n",
      "|        | N |     0     |     0     |     0     |\n",
      "|        -----------------------------------------\n",
      "| Actual | R |     0     |    220    |    230    |\n",
      "         -----------------------------------------\n",
      "|        | L |     0     |    218    |    232    |\n",
      "--------------------------------------------------\n",
      "Class N Performance:\n",
      "   Accuracy  = 1.0\n",
      "   Precision = nan\n",
      "   Recall    = nan\n",
      "   F1-score  = nan\n",
      "\n",
      "Class R Performance:\n",
      "   Accuracy  = 0.6676557863501483\n",
      "   Precision = 0.502283105022831\n",
      "   Recall    = 0.4888888888888889\n",
      "   F1-score  = 0.49549549549549554\n",
      "\n",
      "Class L Performance:\n",
      "   Accuracy  = 0.6676557863501483\n",
      "   Precision = 0.5021645021645021\n",
      "   Recall    = 0.5155555555555555\n",
      "   F1-score  = 0.5087719298245613\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.6676557863501483, 0.6676557863501483],\n",
       " [nan, 0.502283105022831, 0.5021645021645021],\n",
       " [nan, 0.4888888888888889, 0.5155555555555555],\n",
       " [nan, 0.49549549549549554, 0.5087719298245613]]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials  = [0, 15, 15, 0]     # Number of each class (None, Right, Left, Down)\n",
    "t_cue = 3\n",
    "classification_cycle_period = 0.1\n",
    "\n",
    "decision_threshold = 0\n",
    "\n",
    "events_id = {'none': 0, 'right': 1, 'left': 2}\n",
    "\n",
    "def confusion_matrix(TP,FN,FP,TN):\n",
    "    # -- |Results calculation| --\n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = np.NaN\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = np.NaN\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "        \n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------')\n",
    "    print('|            |       Predicted       |')\n",
    "    print('|            -------------------------   Accuracy  = {0:}'.format(accuracy))\n",
    "    print('|            |     P     |     N     |')\n",
    "    print('--------------------------------------   Precision = {0:}'.format(precision))\n",
    "    print(\"|        | P |   {0:^5d}   |   {1:^5d}   |   Recall    = {2:}\".format(TP, FN, recall))\n",
    "    print('| Actual -----------------------------')\n",
    "    print(\"|        | N |   {0:^5d}   |   {1:^5d}   |   F1-score  = {2:}\".format(FP, TN, f1))\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "# -- |Create random label sequence| --\n",
    "labels = np.zeros(n_trials[0], dtype='int')\n",
    "for i in range(1,len(n_trials)):\n",
    "    labels = np.concatenate((labels,np.full(n_trials[i],i, dtype='int')))\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "j = 0\n",
    "p = []\n",
    "Pscores = np.array([0,0])\n",
    "Nscores = 0\n",
    "Pscores_history = []\n",
    "Nscores_history = []\n",
    "while j < len(labels):\n",
    "    label = labels[j]\n",
    "\n",
    "    for i in range(30):\n",
    "        prob = np.random.rand()\n",
    "        p = [prob, 1-prob]\n",
    "\n",
    "        if np.abs(p[0] - p[1]) > decision_threshold:\n",
    "            Pscores[np.argmax(p)] += 1\n",
    "        else:\n",
    "            Nscores += 1\n",
    "\n",
    "    Pscores_history.append([label, Pscores])\n",
    "    Nscores_history.append([label, Nscores])\n",
    "\n",
    "    Pscores = np.array([0,0])\n",
    "    Nscores = 0\n",
    "\n",
    "    j += 1\n",
    "\n",
    "Pscores_history = np.array(Pscores_history, dtype='object')\n",
    "Nscores_history = np.array(Nscores_history)\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "for l in range(np.max(list(events_id.values())) + 1):\n",
    "    Pscores_total = np.array([sh[1] for sh in Pscores_history if sh[0] == l])\n",
    "    Pscores_total = np.sum(Pscores_total, axis = 0)\n",
    "    if Pscores_total.all() == 0:\n",
    "        Pscores_total = np.array([0,0])\n",
    "    positive.append(Pscores_total)\n",
    "\n",
    "    Nscores_total = np.array([sh[1] for sh in Nscores_history if sh[0] == l])\n",
    "    Nscores_total = np.sum(Nscores_total, axis = 0)\n",
    "    negative.append(Nscores_total)\n",
    "\n",
    "positive = np.array(positive, dtype = 'int')\n",
    "negative = np.array([negative], dtype = 'int').T\n",
    "\n",
    "matrix = np.concatenate((negative,positive),axis=1)\n",
    "multiclass_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_confusion_matrix(matrix, class_name = ['N','R','L']):\n",
    "    '''Display Confusion Matrix'''\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------------------')\n",
    "    print('|            |             Predicted             |')\n",
    "    print('|            -------------------------------------')\n",
    "    print('|            |     {0}     |     {1}     |     {2}     |'.format(class_name[0],class_name[1],class_name[2]))\n",
    "    print('--------------------------------------------------')\n",
    "    print(\"|        | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[0],matrix[0,0],matrix[0,1],matrix[0,2]))\n",
    "    print('|        -----------------------------------------')\n",
    "    print(\"| Actual | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[1],matrix[1,0],matrix[1,1],matrix[1,2]))\n",
    "    print('         -----------------------------------------')\n",
    "    print(\"|        | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[2],matrix[2,0],matrix[2,1],matrix[2,2]))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score  = []\n",
    "    # -- |Results calculation| --\n",
    "    for i in range(matrix.shape[0]):\n",
    "        TP = matrix[i,i]\n",
    "        FN = np.sum(matrix[i,:]) - matrix[i,i]\n",
    "        FP = np.sum(matrix[:,i]) - matrix[i,i]\n",
    "        TN = np.sum(matrix) - matrix[i,i]\n",
    "\n",
    "        acc = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "        if TP + FP == 0:\n",
    "            pre = np.NaN\n",
    "        else:\n",
    "            pre = TP/(TP + FP)\n",
    "        \n",
    "        if TP + FN == 0:\n",
    "            rec = np.NaN\n",
    "        else:\n",
    "            rec = TP/(TP + FN)\n",
    "            \n",
    "        f1 = 2*(pre*rec)/(pre + rec)\n",
    "\n",
    "        print(f'Class {class_name[i]} Performance:')\n",
    "        print(f'   Accuracy  = {acc}')\n",
    "        print(f'   Precision = {pre}')\n",
    "        print(f'   Recall    = {rec}')\n",
    "        print(f'   F1-score  = {f1}\\n')\n",
    "\n",
    "        accuracy.append(acc)\n",
    "        precision.append(pre)\n",
    "        recall.append(rec)\n",
    "        f1_score.append(f1)\n",
    "\n",
    "\n",
    "    return [accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.],\n",
       "       [  0., 220., 230.],\n",
       "       [  0., 239., 211.]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.concatenate((negative,positive),axis=1)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16],\n",
       "       [234],\n",
       "       [212]])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   6],\n",
       "       [111, 105],\n",
       "       [118, 120]])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_threshold = 0.5\n",
    "Pscores = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = np.random.rand()\n",
    "p = [prob, 1-prob]\n",
    "\n",
    "if np.abs(p[0] - p[1]) > decision_threshold:\n",
    "    Pscores[np.argmax(p)] += 1\n",
    "Pscores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
