{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "from psychopy import visual, core\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "IP_address = \"169.254.85.188\"\n",
    "\n",
    "# --|Connect to the robot|--\n",
    "rtde_c = rtde_control.RTDEControlInterface(IP_address) \n",
    "rtde_r = rtde_receive.RTDEReceiveInterface(IP_address)  \n",
    "\n",
    "speed = [0,0,0,0,0,0]\n",
    "\n",
    "rest_period_length = 1\n",
    "\n",
    "\n",
    "def d2r(degrees):\n",
    "    return degrees * (math.pi / 180)\n",
    "\n",
    "def state(s):\n",
    "    state.value = s\n",
    "def t_rest(t):\n",
    "    t_rest.value = t\n",
    "def dir(d):\n",
    "    dir.value = d\n",
    "\n",
    "state(0)\n",
    "t_rest(0)\n",
    "dir(0)\n",
    "\n",
    "def velo_joint(joint, direction):\n",
    "    t_start = rtde_c.initPeriod()\n",
    "    speed[joint] = 0.75 * direction\n",
    "    rtde_c.speedJ(speed, 0.01, 1.0/500)\n",
    "    if rtde_r.getActualQ()[joint] < d2r(-100) and direction == -1:\n",
    "        direction = 1\n",
    "        rtde_c.speedStop()\n",
    "        print(\"Change Direction 1\")\n",
    "    if rtde_r.getActualQ()[joint] > d2r(100) and direction == 1:\n",
    "        direction = -1\n",
    "        rtde_c.speedStop()\n",
    "        print(\"Change Direction -1\")\n",
    "    rtde_c.waitPeriod(t_start)\n",
    "    return direction\n",
    "\n",
    "def FSM(current_joint, blink, MI_classification_result):\n",
    "    if state.value == 0:\n",
    "        if blink == 1:\n",
    "            state(1)\n",
    "    elif state.value == 1:\n",
    "        if MI_classification_result != 0:\n",
    "            dir(MI_classification_result)\n",
    "            state(2)\n",
    "    elif state.value == 2:\n",
    "        velo_joint(current_joint, dir.value)\n",
    "\n",
    "        if blink == 1:\n",
    "            t_rest(time.perf_counter() + rest_period_length)\n",
    "            state(3)\n",
    "    elif state.value == 3:\n",
    "        if time.perf_counter() > t_rest.value:\n",
    "            state(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(5//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#751818', 'gray'], dtype='<U7')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pscores = np.array([2,8])\n",
    "k = 3\n",
    "\n",
    "np.where(np.array([k,k]) < Pscores,'#751818','gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "b = 1\n",
    "\n",
    "c = a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores calculation simulation (Double model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Model Performance\n",
      "Confusion Matrix\n",
      "--------------------------------------\n",
      "|            |       Predicted       |\n",
      "|            -------------------------   Accuracy  = 0.4288888888888889\n",
      "|            |     P     |     N     |\n",
      "--------------------------------------   Precision = 0.24564183835182252\n",
      "|        | P |    155    |    295    |   Recall    = 0.34444444444444444\n",
      "| Actual -----------------------------\n",
      "|        | N |    476    |    424    |   F1-score  = 0.28677150786308975\n",
      "--------------------------------------\n",
      "Right Model Performance\n",
      "Confusion Matrix\n",
      "--------------------------------------\n",
      "|            |       Predicted       |\n",
      "|            -------------------------   Accuracy  = 0.585925925925926\n",
      "|            |     P     |     N     |\n",
      "--------------------------------------   Precision = 0.41362916006339145\n",
      "|        | P |    261    |    189    |   Recall    = 0.58\n",
      "| Actual -----------------------------\n",
      "|        | N |    370    |    530    |   F1-score  = 0.4828862164662349\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.585925925925926, 0.41362916006339145, 0.58, 0.4828862164662349]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials  = [15, 15, 15, 0]     # Number of each class (None, Right, Left, Down)\n",
    "t_cue = 3\n",
    "classification_cycle_period = 0.1\n",
    "\n",
    "events_id = {'none': 0, 'right': 1, 'left': 2}\n",
    "\n",
    "def confusion_matrix(TP,FN,FP,TN):\n",
    "    # -- |Results calculation| --\n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = np.NaN\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = np.NaN\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "        \n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------')\n",
    "    print('|            |       Predicted       |')\n",
    "    print('|            -------------------------   Accuracy  = {0:}'.format(accuracy))\n",
    "    print('|            |     P     |     N     |')\n",
    "    print('--------------------------------------   Precision = {0:}'.format(precision))\n",
    "    print(\"|        | P |   {0:^5d}   |   {1:^5d}   |   Recall    = {2:}\".format(TP, FN, recall))\n",
    "    print('| Actual -----------------------------')\n",
    "    print(\"|        | N |   {0:^5d}   |   {1:^5d}   |   F1-score  = {2:}\".format(FP, TN, f1))\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "# -- |Create random label sequence| --\n",
    "labels = np.zeros(n_trials[0], dtype='int')\n",
    "for i in range(1,len(n_trials)):\n",
    "    labels = np.concatenate((labels,np.full(n_trials[i],i, dtype='int')))\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "j = 0\n",
    "p = []\n",
    "Pscores = np.array([0,0])\n",
    "Nscores = np.array([0,0])\n",
    "Pscores_history = []\n",
    "Nscores_history = []\n",
    "while j < len(labels):\n",
    "    label = labels[j]\n",
    "    for i in range(2):\n",
    "        Pscores[i] = np.random.randint(0,30)\n",
    "        Nscores[i] = 30 - Pscores[i]\n",
    "    Pscores_history.append([label, Pscores])\n",
    "    Nscores_history.append([label, Nscores])\n",
    "    Pscores = np.array([0,0])\n",
    "    Nscores = np.array([0,0])\n",
    "    j += 1\n",
    "\n",
    "Pscores_history = np.array(Pscores_history, dtype='object')\n",
    "Nscores_history = np.array(Nscores_history, dtype='object')\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "for l in range(np.max(list(events_id.values())) + 1):\n",
    "    Pscores_total = np.array([sh[1] for sh in Pscores_history if sh[0] == l])\n",
    "    Pscores_total = np.sum(Pscores_total, axis = 0)\n",
    "    positive.append(Pscores_total)\n",
    "\n",
    "    Nscores_total = np.array([sh[1] for sh in Nscores_history if sh[0] == l])\n",
    "    Nscores_total = np.sum(Nscores_total, axis = 0)\n",
    "    negative.append(Nscores_total)\n",
    "\n",
    "positive = np.array(positive)\n",
    "negative = np.array(negative)\n",
    "print('Left Model Performance')\n",
    "confusion_matrix(positive[events_id['left']][0],negative[events_id['left']][0],(np.sum(positive[:,0]) - positive[events_id['left']])[0],(np.sum(negative[:,0]) - negative[events_id['left']])[0])\n",
    "print('Right Model Performance')\n",
    "confusion_matrix(positive[events_id['right']][1],negative[events_id['right']][1],(np.sum(positive[:,0]) - positive[events_id['right']])[1],(np.sum(negative[:,0]) - negative[events_id['right']])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores calculation simulation (Single model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "--------------------------------------------------\n",
      "|            |             Predicted             |\n",
      "|            -------------------------------------\n",
      "|            |     N     |     R     |     L     |\n",
      "--------------------------------------------------\n",
      "|        | N |     0     |     0     |     0     |\n",
      "|        -----------------------------------------\n",
      "| Actual | R |     0     |    220    |    230    |\n",
      "         -----------------------------------------\n",
      "|        | L |     0     |    218    |    232    |\n",
      "--------------------------------------------------\n",
      "Class N Performance:\n",
      "   Accuracy  = 1.0\n",
      "   Precision = nan\n",
      "   Recall    = nan\n",
      "   F1-score  = nan\n",
      "\n",
      "Class R Performance:\n",
      "   Accuracy  = 0.6676557863501483\n",
      "   Precision = 0.502283105022831\n",
      "   Recall    = 0.4888888888888889\n",
      "   F1-score  = 0.49549549549549554\n",
      "\n",
      "Class L Performance:\n",
      "   Accuracy  = 0.6676557863501483\n",
      "   Precision = 0.5021645021645021\n",
      "   Recall    = 0.5155555555555555\n",
      "   F1-score  = 0.5087719298245613\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.6676557863501483, 0.6676557863501483],\n",
       " [nan, 0.502283105022831, 0.5021645021645021],\n",
       " [nan, 0.4888888888888889, 0.5155555555555555],\n",
       " [nan, 0.49549549549549554, 0.5087719298245613]]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials  = [0, 15, 15, 0]     # Number of each class (None, Right, Left, Down)\n",
    "t_cue = 3\n",
    "classification_cycle_period = 0.1\n",
    "\n",
    "decision_threshold = 0\n",
    "\n",
    "events_id = {'none': 0, 'right': 1, 'left': 2}\n",
    "\n",
    "def confusion_matrix(TP,FN,FP,TN):\n",
    "    # -- |Results calculation| --\n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = np.NaN\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = np.NaN\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "        \n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------')\n",
    "    print('|            |       Predicted       |')\n",
    "    print('|            -------------------------   Accuracy  = {0:}'.format(accuracy))\n",
    "    print('|            |     P     |     N     |')\n",
    "    print('--------------------------------------   Precision = {0:}'.format(precision))\n",
    "    print(\"|        | P |   {0:^5d}   |   {1:^5d}   |   Recall    = {2:}\".format(TP, FN, recall))\n",
    "    print('| Actual -----------------------------')\n",
    "    print(\"|        | N |   {0:^5d}   |   {1:^5d}   |   F1-score  = {2:}\".format(FP, TN, f1))\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "# -- |Create random label sequence| --\n",
    "labels = np.zeros(n_trials[0], dtype='int')\n",
    "for i in range(1,len(n_trials)):\n",
    "    labels = np.concatenate((labels,np.full(n_trials[i],i, dtype='int')))\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "j = 0\n",
    "p = []\n",
    "Pscores = np.array([0,0])\n",
    "Nscores = 0\n",
    "Pscores_history = []\n",
    "Nscores_history = []\n",
    "while j < len(labels):\n",
    "    label = labels[j]\n",
    "\n",
    "    for i in range(30):\n",
    "        prob = np.random.rand()\n",
    "        p = [prob, 1-prob]\n",
    "\n",
    "        if np.abs(p[0] - p[1]) > decision_threshold:\n",
    "            Pscores[np.argmax(p)] += 1\n",
    "        else:\n",
    "            Nscores += 1\n",
    "\n",
    "    Pscores_history.append([label, Pscores])\n",
    "    Nscores_history.append([label, Nscores])\n",
    "\n",
    "    Pscores = np.array([0,0])\n",
    "    Nscores = 0\n",
    "\n",
    "    j += 1\n",
    "\n",
    "Pscores_history = np.array(Pscores_history, dtype='object')\n",
    "Nscores_history = np.array(Nscores_history)\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "for l in range(np.max(list(events_id.values())) + 1):\n",
    "    Pscores_total = np.array([sh[1] for sh in Pscores_history if sh[0] == l])\n",
    "    Pscores_total = np.sum(Pscores_total, axis = 0)\n",
    "    if Pscores_total.all() == 0:\n",
    "        Pscores_total = np.array([0,0])\n",
    "    positive.append(Pscores_total)\n",
    "\n",
    "    Nscores_total = np.array([sh[1] for sh in Nscores_history if sh[0] == l])\n",
    "    Nscores_total = np.sum(Nscores_total, axis = 0)\n",
    "    negative.append(Nscores_total)\n",
    "\n",
    "positive = np.array(positive, dtype = 'int')\n",
    "negative = np.array([negative], dtype = 'int').T\n",
    "\n",
    "matrix = np.concatenate((negative,positive),axis=1)\n",
    "multiclass_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_confusion_matrix(matrix, class_name = ['N','R','L']):\n",
    "    '''Display Confusion Matrix'''\n",
    "    # -- |Results display| --\n",
    "    print('Confusion Matrix')\n",
    "    print('--------------------------------------------------')\n",
    "    print('|            |             Predicted             |')\n",
    "    print('|            -------------------------------------')\n",
    "    print('|            |     {0}     |     {1}     |     {2}     |'.format(class_name[0],class_name[1],class_name[2]))\n",
    "    print('--------------------------------------------------')\n",
    "    print(\"|        | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[0],matrix[0,0],matrix[0,1],matrix[0,2]))\n",
    "    print('|        -----------------------------------------')\n",
    "    print(\"| Actual | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[1],matrix[1,0],matrix[1,1],matrix[1,2]))\n",
    "    print('         -----------------------------------------')\n",
    "    print(\"|        | {0} |   {1:^5d}   |   {2:^5d}   |   {3:^5d}   |\".format(class_name[2],matrix[2,0],matrix[2,1],matrix[2,2]))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score  = []\n",
    "    # -- |Results calculation| --\n",
    "    for i in range(matrix.shape[0]):\n",
    "        TP = matrix[i,i]\n",
    "        FN = np.sum(matrix[i,:]) - matrix[i,i]\n",
    "        FP = np.sum(matrix[:,i]) - matrix[i,i]\n",
    "        TN = np.sum(matrix) - matrix[i,i]\n",
    "\n",
    "        acc = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "        if TP + FP == 0:\n",
    "            pre = np.NaN\n",
    "        else:\n",
    "            pre = TP/(TP + FP)\n",
    "        \n",
    "        if TP + FN == 0:\n",
    "            rec = np.NaN\n",
    "        else:\n",
    "            rec = TP/(TP + FN)\n",
    "            \n",
    "        f1 = 2*(pre*rec)/(pre + rec)\n",
    "\n",
    "        print(f'Class {class_name[i]} Performance:')\n",
    "        print(f'   Accuracy  = {acc}')\n",
    "        print(f'   Precision = {pre}')\n",
    "        print(f'   Recall    = {rec}')\n",
    "        print(f'   F1-score  = {f1}\\n')\n",
    "\n",
    "        accuracy.append(acc)\n",
    "        precision.append(pre)\n",
    "        recall.append(rec)\n",
    "        f1_score.append(f1)\n",
    "\n",
    "\n",
    "    return [accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.],\n",
       "       [  0., 220., 230.],\n",
       "       [  0., 239., 211.]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.concatenate((negative,positive),axis=1)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16],\n",
       "       [234],\n",
       "       [212]])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   6],\n",
       "       [111, 105],\n",
       "       [118, 120]])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_threshold = 0.5\n",
    "Pscores = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = np.random.rand()\n",
    "p = [prob, 1-prob]\n",
    "\n",
    "if np.abs(p[0] - p[1]) > decision_threshold:\n",
    "    Pscores[np.argmax(p)] += 1\n",
    "Pscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 750)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "timewindow_lenght = 3\n",
    "t_baseline_online_B = 0.5\n",
    "\n",
    "# -- |Time Window Initialization| --\n",
    "timewindow = np.full((7,int(250*timewindow_lenght)),1e-15)\n",
    "channels = ['C3','Cz','C4','Pz','PO7','PO8','EOG'] # Set your target EEG channel name\n",
    "info = mne.create_info(\n",
    "    ch_names= channels,\n",
    "    ch_types= ['eeg']*(len(channels) - 1) + ['eog'],\n",
    "    sfreq= 250,  # OpenBCI Frequency acquistion\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "timewindow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "timewindow_mne = mne.io.RawArray(timewindow, info, verbose=False)\n",
    "timewindow_mne_B = timewindow_mne.copy().set_eeg_reference('average', verbose=False)\n",
    "timewindow_mne_B = timewindow_mne_B.filter(l_freq=2.0, h_freq=15.0, fir_design='firwin',picks ='all', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_data_B = timewindow_mne_B.get_data()\n",
    "realtime_data_B = realtime_data_B - np.array([np.mean(realtime_data_B[:int((t_baseline_online_B)*250)], axis = 1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "if sum(realtime_data_B[-1] > threshold) >= 2: blink = 1\n",
    "else: blink = 0\n",
    "\n",
    "blink"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
